{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqrpBxlL-VR8"
   },
   "source": [
    "## Please complete before submission:\n",
    "\n",
    "**Name:** Shambhavi Singh\n",
    "\n",
    "**Student Number:** 2711327S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWZ4t4Ut91ur"
   },
   "source": [
    "# TextAs Data Coursework\n",
    "\n",
    "Please fill in this Google Colab by following the prompts from the coursework specification document and inserting your code in each relevant section.\n",
    "\n",
    "- You should submit this notebook together with your report. (Two separate files)\n",
    "- Specifcally you will submit **both a PDF with the report (so we can easily read it) and a .ipynb file containing the source code of your experiments as evidence**. Please do clean up your code where possible before submitting it.\n",
    "- You may add whatever additional code and text blocks as needed (perhaps with [nice formatting](https://colab.research.google.com/notebooks/markdown_guide.ipynb)). Please keep the major headings (for the question numbers) the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EstYvRPS_Crg"
   },
   "source": [
    "As with labs, please remember to **Save a Copy to Drive** when you start working on this so that it is saved. Completing the labs provides essential knowledge for the successful completion of the coursework. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DyFYH3v7-ix0"
   },
   "source": [
    "## Downloading and loading Data\n",
    "\n",
    "This code loads the prepared split of the Reddit data into training, validation and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tG_zJqYH9sTd",
    "outputId": "6beecf89-85a6-4d4d-aac7-a4ad076ba07f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EapVNOIV84tPnQuuFBNgG9UBYIWipQ9JL4QTfSgRtIacBw?download=1\n",
      "unzip:  cannot find or open reddit_data_split.zip, reddit_data_split.zip.zip or reddit_data_split.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!wget -O reddit_data_split.zip https://gla-my.sharepoint.com/:u:/g/personal/jake_lever_glasgow_ac_uk/EapVNOIV84tPnQuuFBNgG9UBYIWipQ9JL4QTfSgRtIacBw?download=1\n",
    "!unzip -o reddit_data_split.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xCezGTgdRYkj",
    "outputId": "6ac0bbc0-ec5c-43f7-acfb-7eca3826edb1"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reddit_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/g4/12987c8n3dn31sx6b2mw7v140000gn/T/ipykernel_5173/958726360.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reddit_train.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reddit_val.json'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reddit_train.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('reddit_train.json') as f:\n",
    "    train_data = json.load(f)\n",
    "with open('reddit_val.json') as f:\n",
    "    validation_data = json.load(f)\n",
    "with open('reddit_test.json') as f:\n",
    "    test_data = json.load(f)\n",
    "\n",
    "print(\"Number of posts in training data:\", len(train_data))\n",
    "print(\"Number of posts in validation data:\", len(validation_data))\n",
    "print(\"Number of posts in test data:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7txBmrCG_tKr"
   },
   "source": [
    "## Q1:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK9u5izk_wSh"
   },
   "source": [
    "### Q1a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EPyrHiW9YDN",
    "outputId": "a49333ee-e3ae-416a-e6d4-a597cfeb2777"
   },
   "outputs": [],
   "source": [
    "#Grouping the dataset according to the subreddit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Grouping the train data\n",
    "train_data_df = pd.DataFrame(train_data)\n",
    "\n",
    "train_data_df1=train_data_df.groupby([\"subreddit\"]).count()\n",
    "print(\"\\nTrain data: \")\n",
    "print(train_data_df1['title'])\n",
    "\n",
    "#Grouping the validation data\n",
    "validation_data_df = pd.DataFrame(validation_data)\n",
    "validation_data_df1=validation_data_df.groupby([\"subreddit\"]).count()\n",
    "print(\"\\nValidation data: \")\n",
    "print(validation_data_df1['title'])\n",
    "\n",
    "#Grouping the test data\n",
    "test_data_df = pd.DataFrame(test_data)\n",
    "test_data_df1=test_data_df.groupby([\"subreddit\"]).count()\n",
    "print(\"\\nTest data: \")\n",
    "print(test_data_df1['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQaSIxai_8dQ"
   },
   "source": [
    "### Q1b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D58u8vCp-Ned"
   },
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OB4HEHES-JkM",
    "outputId": "0e0ae345-e85c-49b8-e1b0-cac2b1c05ed7"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the medium english model. \n",
    "# We will use this model to get embedding features for tokens later.\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "nlp.remove_pipe('tagger')\n",
    "nlp.remove_pipe('parser')\n",
    "\n",
    "# Download a stopword list\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkEi5hSX-LLR"
   },
   "outputs": [],
   "source": [
    "#Preprocessing of the data\n",
    "def text_pipeline_spacy(text):\n",
    "    tokens = []\n",
    "    doc = nlp(text)\n",
    "    for t in doc:\n",
    "       if not t.is_stop and not t.is_space:\n",
    "            tokens.append(t.lemma_.lower())\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9JeHta1IqqT"
   },
   "source": [
    "Creating the evaluation summary function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9V5e4TpIp-M"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "def evaluation_summary(description, true_labels, predictions):\n",
    "\n",
    "  print(\"Evaluation for: \" + description)\n",
    "  precision = precision_score(predictions, true_labels, average='weighted')\n",
    "  recall = recall_score(predictions, true_labels, average='weighted')\n",
    "  accuracy = accuracy_score(predictions, true_labels)\n",
    "  print(\"Classifier '%s' has Acc=%0.3f P=%0.3f R=%0.3f\" % (description,accuracy,precision,recall))\n",
    "\n",
    "  print(classification_report(true_labels, predictions,  digits=3, zero_division=0)) \n",
    "  print('\\nConfusion matrix:\\n',confusion_matrix(true_labels, predictions)) # Note the order here is true, predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "im-SsHgIRnb2"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Creating a one-hot encoding vectorizer.\n",
    "one_hot_vectorizer = CountVectorizer(tokenizer=text_pipeline_spacy, binary=True)\n",
    "\n",
    "# This creates input features for our classification on all subsets of our collection.\n",
    "train_features = one_hot_vectorizer.fit_transform(train_data_df['body'].tolist())\n",
    "validation_features = one_hot_vectorizer.transform(validation_data_df['body'].tolist())\n",
    "test_features = one_hot_vectorizer.transform(test_data_df['body'].tolist())\n",
    "\n",
    "train_labels = train_data_df['subreddit']\n",
    "validation_labels = validation_data_df['subreddit']\n",
    "test_labels = test_data_df['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ydjdX_YI2y1"
   },
   "source": [
    "Implementation of the classifiers :-   \n",
    "  \n",
    "(i) Dummy Classifier with strategy = \"most frequent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QCZU2IpYI6Bl",
    "outputId": "77b9ecab-0fee-4138-b97d-ae9284ac0bf3"
   },
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "mf_dummy = DummyClassifier(strategy='most_frequent')\n",
    "\n",
    "#Training on the train data\n",
    "mf_dummy.fit(train_features, train_labels)\n",
    "\n",
    "#Evaluation on test data\n",
    "mf_dummy_predicted_labels = mf_dummy.predict(test_features)\n",
    "evaluation_summary(\"Dummy Majority (Test Data)\", test_labels, mf_dummy_predicted_labels)\n",
    "\n",
    "#Evaluation on train data\n",
    "mf_dummy_predicted_labels_train = mf_dummy.predict(train_features)\n",
    "evaluation_summary(\"Dummy Majority (Train Data)\", train_labels, mf_dummy_predicted_labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljoPGgFOPxui"
   },
   "source": [
    "(ii) Dummy Classfier with strategy = \"stratified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5scO9ReXPxC2",
    "outputId": "ea0a2849-1436-4d89-c161-6169edbe76cd"
   },
   "outputs": [],
   "source": [
    "dummy_prior = DummyClassifier(strategy='stratified')\n",
    "\n",
    "#Training on the train data\n",
    "dummy_prior.fit(train_features, train_labels)\n",
    "\n",
    "#Evaluation on the test data\n",
    "dummy_prior_predicted_labels = dummy_prior.predict(test_features)\n",
    "evaluation_summary(\"Dummy Prior (Test Data)\", test_labels, dummy_prior_predicted_labels)\n",
    "\n",
    "#Evaluation on train data\n",
    "dummy_prior_predicted_labels_train = mf_dummy.predict(train_features)\n",
    "evaluation_summary(\"Dummy Majority (Train Data)\", train_labels, dummy_prior_predicted_labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Kg8PAyfQmVB"
   },
   "source": [
    "LogisticRegression with One-hot vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tDZL8cPNQZzc",
    "outputId": "aa0076f0-ecca-4a5e-f865-963fb1fe907e"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#Training on the train data\n",
    "lr_model = lr.fit(train_features, train_labels)\n",
    "\n",
    "#Evaluation on the test data\n",
    "lr_predicted_labels = lr_model.predict(test_features)\n",
    "evaluation_summary(\"LR onehot (Test Data)\", test_labels, lr_predicted_labels)\n",
    "\n",
    "#Evaluation on train data\n",
    "lr_predicted_labels_train = lr_model.predict(train_features)\n",
    "evaluation_summary(\"LR onehot (Train Data)\", train_labels, lr_predicted_labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TFsHTwEQzkp"
   },
   "source": [
    "LogisticRegression with TF-IDF vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1TpBnD_kQwVo",
    "outputId": "6a6b8968-4ff5-4ff1-ba8d-8f8cecf56492"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy\n",
    "\n",
    "#Creating a TF-IDF vetorizer\n",
    "tf_vectorizer = TfidfVectorizer(tokenizer=text_pipeline_spacy, binary=True)\n",
    "\n",
    "# This creates input features for our classification on all subsets of our collection.\n",
    "train_features_lr = tf_vectorizer.fit_transform(train_data_df['body'].tolist())\n",
    "validation_features_lr = tf_vectorizer.transform(validation_data_df['body'].tolist())\n",
    "test_features_lr = tf_vectorizer.transform(test_data_df['body'].tolist())\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#Training on the train data\n",
    "lr_model = lr.fit(train_features_lr, train_labels)\n",
    "\n",
    "#Evaluation on the test data\n",
    "lr_predicted_labels_tf_idf = lr_model.predict(test_features_lr)\n",
    "evaluation_summary(\"LR TF-IDF (Test Data)\", test_labels, lr_predicted_labels_tf_idf)\n",
    "\n",
    "\n",
    "#Evaluation on the train data\n",
    "lr_predicted_labels_train = lr_model.predict(train_features_lr)\n",
    "evaluation_summary(\"LR TF-IDF (Train Data)\", train_labels, lr_predicted_labels_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CYH8o2ntRNnG"
   },
   "source": [
    "SVC Classifier with One-hot vectorization (SVM with RBF kernel, default settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Snkzq8mnRNyO",
    "outputId": "190af64e-3239-45d7-c286-3ed387d801df"
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "lr = svm.SVC(kernel='rbf')\n",
    "\n",
    "#Training on the train data\n",
    "lr_model = lr.fit(train_features, train_labels)\n",
    "\n",
    "#Evaluation on the test data\n",
    "svc_predicted_labels = lr_model.predict(test_features)\n",
    "evaluation_summary(\"SVC onehot (Test Data)\", test_labels, svc_predicted_labels)\n",
    "\n",
    "#Evaluation on the train data\n",
    "lr_predicted_labels_train = lr_model.predict(train_features)\n",
    "evaluation_summary(\"SVC onehot (Train Data)\", train_labels, lr_predicted_labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYoA7Hscau-V"
   },
   "source": [
    "Plotting the graph of f1 score vs subreddit for the best performing classifier i.e., Logistic Regression with TF-IDF vectorization ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585
    },
    "id": "baHYursgV-jm",
    "outputId": "4af38ac3-89b7-49fc-f52d-4208e5cfd8c5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Graph plot for the best performing classifier above\n",
    "labels = ['Coffee','HydroHomies','NinetendoSwitch','PS4','Soda','antiMLM','pcgaming','tea','xbox']\n",
    "f1score = f1_score(lr_predicted_labels_tf_idf, test_labels, average=None)\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax=fig.add_subplot(111)\n",
    "plt.bar(labels, f1score)\n",
    "ax.set_xticklabels(labels, rotation=90)\n",
    "plt.title(\"Graph plot for the best performing classifier\")\n",
    "plt.xlabel(\"subreddit\", fontsize=15)\n",
    "plt.ylabel(\"F1-score\", fontsize=15)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YBMJdw_j_8fx"
   },
   "source": [
    "### Q1c:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PN94V_GnRshy"
   },
   "source": [
    "Own classifier/tokenization/normalisations approach,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "5FDubyEqRsyF",
    "outputId": "83a7aa9c-3723-4046-9fed-759f608f7e61"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "#Training on the tain data\n",
    "nb_model = classifier.fit(train_features_lr, train_labels)\n",
    "\n",
    "#Evaluation on the test data\n",
    "test_predicted_labels = nb_model.predict(test_features_lr)\n",
    "evaluation_summary(\"One-hot Naive Bayes (Test Data)\",  test_predicted_labels, test_labels)\n",
    "\n",
    "#Evaluation on the train data\n",
    "train_predicted_labels = nb_model.predict(train_features_lr)\n",
    "evaluation_summary(\"One-hot Naive Bayes (Train Data)\",  train_predicted_labels, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZcRes8WAOo6"
   },
   "source": [
    "## Q2:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZuAxwU0IABir"
   },
   "source": [
    "### Q2a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dBe-rkfPUNtq"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"For data grouped by feature, select subset of data at a provided key.    \"\"\"\n",
    "\n",
    "    def __init__(self, key):\n",
    "        self.key = key\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data_dict):\n",
    "        return data_dict[self.key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CyryhAKyUgg0"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "prediction_pipeline = Pipeline([\n",
    "              ('selector', Selector(key='body')),\n",
    "              ('tf-idf', TfidfVectorizer()),\n",
    "              ('logreg', LogisticRegression())\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6aWgwHGVUuFR",
    "outputId": "f50f802a-0260-496f-d385-98869c150f36"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "params={\n",
    "        'logreg__penalty' : ['l2'], \n",
    "        'logreg__C'       : np.logspace(-3,3,7),\n",
    "        'logreg__solver'  : ['liblinear'],     \n",
    "        'logreg__max_iter': [10000],\n",
    "        'tf-idf__max_features' : [10000],\n",
    "        'tf-idf__sublinear_tf': [True] \n",
    "        }\n",
    "\n",
    "grid_search = GridSearchCV(prediction_pipeline, param_grid = params, n_jobs=1, verbose=1, scoring='f1_macro', cv=2)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in prediction_pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "print(params)\n",
    "\n",
    "#Trained on validation data\n",
    "grid_model=grid_search.fit(validation_data_df, validation_labels)\n",
    "grid_predicted_labels = grid_model.predict(test_data_df)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(params.keys()):\n",
    "  print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YiOQL-cSxIb9"
   },
   "source": [
    "Testing the model again after tuning the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yk13uwJzvP5j",
    "outputId": "38d6db1d-f366-4ac5-f7f4-a9adddd2d521"
   },
   "outputs": [],
   "source": [
    "#Creating a TF-IDF vetorizer\n",
    "tf_vectorizer = TfidfVectorizer(tokenizer=text_pipeline_spacy, max_features=10000,sublinear_tf=True)\n",
    "\n",
    "# This creates input features for our classification on all subsets of our collection.\n",
    "train_features_lr = tf_vectorizer.fit_transform(train_data_df['body'].tolist())\n",
    "validation_features_lr = tf_vectorizer.transform(validation_data_df['body'].tolist())\n",
    "test_features_lr = tf_vectorizer.transform(test_data_df['body'].tolist())\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "#Training on the train data\n",
    "lr_model = lr.fit(train_features_lr, train_labels)\n",
    "\n",
    "#Evaluation on the test data\n",
    "lr_predicted_labels_tf_idf = lr_model.predict(test_features_lr)\n",
    "evaluation_summary(\"LR TF-IDF (Test Data) After Tuning\", test_labels, lr_predicted_labels_tf_idf)\n",
    "\n",
    "#Evaluation on the train data\n",
    "lr_predicted_labels_train = lr_model.predict(train_features_lr)\n",
    "evaluation_summary(\"LR TF-IDF (Train Data) After Tuning\", train_labels, lr_predicted_labels_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIsRTiW-ABs8"
   },
   "source": [
    "### Q2b:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iROEtCywFQLD"
   },
   "source": [
    "Error Analysis: Explored the mismatch for labels between the predictions and true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 478
    },
    "id": "ge4lC6v7-rbT",
    "outputId": "38129447-995e-4bd4-e086-c50df2d93372"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "predicted_list= lr_predicted_labels_tf_idf.tolist()\n",
    "label_test_list=test_labels.tolist()\n",
    "mismatch=[i for i, j in zip(predicted_list, label_test_list) if  i!=j]\n",
    "print(\"Mismatch has occured for the these labels:\",mismatch)\n",
    "print(\"Count of the labels mimatched:\",len(mismatch))\n",
    "\n",
    "predicted_list1 = pd.Series(lr_predicted_labels_tf_idf) \n",
    "dummy_df = test_data_df\n",
    "dummy_df = dummy_df.assign(predict=predicted_list1.values)\n",
    "dummy_df = dummy_df[dummy_df['subreddit']!= dummy_df['predict']]\n",
    "dummy_df[['subreddit', 'predict','body']]\n",
    "\n",
    "# Counting label mismatch ,Code reference from: https://datascience.stackexchange.com/questions/37899/sklearn-svm-how-to-get-a-list-of-the-wrong-predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWs7YqOOAbLp"
   },
   "source": [
    "## Q3:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOpWB9pMAcri"
   },
   "source": [
    "### Q3a:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrqiNV5LHV0a"
   },
   "source": [
    "Features selected to add in the classifiers and the reason behind their selction :-\n",
    "\n",
    "**title** : The title of the post. This is interrelated with body, so it may help in the training of the model.\n",
    "\n",
    "**author** : the username of the poster. The same sentiment polarity may appear when the same user appears."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ymz5BE7NAgZM"
   },
   "source": [
    "### Q3b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TAJCbZg4HtUA"
   },
   "outputs": [],
   "source": [
    "# add only title\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "\n",
    "prediction_pipeline_union = {\n",
    "    'title_feature': Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "          transformer_list=[\n",
    "            ('title', Pipeline([\n",
    "              ('selector', Selector(key='title')),\n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "            ('body', Pipeline([\n",
    "              ('selector', Selector(key='body')), \n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "        ])\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    'author_feature': Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "          transformer_list=[\n",
    "            ('author', Pipeline([\n",
    "              ('selector', Selector(key='author')),\n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "            ('body', Pipeline([\n",
    "              ('selector', Selector(key='body')), \n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "        ])\n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    'combined_feature': Pipeline([\n",
    "        ('union', FeatureUnion(\n",
    "          transformer_list=[\n",
    "            ('title', Pipeline([\n",
    "              ('selector', Selector(key='title')),\n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "            ('author', Pipeline([\n",
    "              ('selector', Selector(key='author')),\n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "            ('body', Pipeline([\n",
    "              ('selector', Selector(key='body')), \n",
    "              ('tfidf', TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)), \n",
    "              ])),\n",
    "        ])\n",
    "        )\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UD4gyCu9VDfT",
    "outputId": "9b48b815-c918-41cd-903d-206e80f65db3"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "for i in prediction_pipeline_union:\n",
    "  print(i)\n",
    "  prediction_pipeline_union[i].fit(train_data_df)\n",
    "  tfidf_train=prediction_pipeline_union[i].transform(train_data_df)\n",
    "  tfidf_test=prediction_pipeline_union[i].transform(test_data_df)\n",
    "\n",
    "  lr_tuned = LogisticRegression(C=1000).fit(tfidf_train, train_labels)\n",
    "  predicted=lr_tuned.predict(tfidf_test)\n",
    "  evaluation_summary(\"\\nLogistic Regession with TFIDF feature tuning\",predicted ,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pvM8ZBNiVcjN"
   },
   "source": [
    "Adding only one feature with body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fkBPlQeIVITI",
    "outputId": "8585b751-b60c-404e-9d4d-0f89b7bbc3a2"
   },
   "outputs": [],
   "source": [
    "# add only title\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "text_features = ['body','title']\n",
    "text_transformer = TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=True, max_features=10000, max_df=1200)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        \n",
    "        ('tfidf_1', text_transformer, 'body'),\n",
    "        ('tfidf_2', text_transformer, 'title'),],\n",
    "                    remainder='drop')\n",
    "\n",
    "\n",
    "## Run evaluation with classifier\n",
    "def evaluateClassifier(classif):\n",
    "  clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', classif)])\n",
    "\n",
    "  clf.fit(train_data_df, train_labels)\n",
    "  y_pred = clf.predict(test_data_df)\n",
    "  print(metrics.classification_report(test_labels, y_pred, zero_division=0))\n",
    "\n",
    "evaluateClassifier(LogisticRegression(solver='saga', max_iter = 1000, C=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdyVCztEVhO9"
   },
   "source": [
    "Adding two features ; title and author with body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "topqQZ66IE6M",
    "outputId": "82982333-78d1-49c8-b851-b39f39a0de97"
   },
   "outputs": [],
   "source": [
    "# add title and author\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "text_features = ['body','title','author']\n",
    "text_transformer = TfidfVectorizer(tokenizer=text_pipeline_spacy,sublinear_tf=False, max_features=3000, max_df=1200)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('tfidf_1', text_transformer, 'body'),\n",
    "        ('tfidf_2', text_transformer, 'title'),\n",
    "        ('tfidf_3', text_transformer, 'author')],\n",
    "                    remainder='drop')\n",
    "\n",
    "\n",
    "## Run evaluation with classifier\n",
    "def evaluateClassifier(classif):\n",
    "  clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                        ('classifier', classif)])\n",
    "\n",
    "  clf.fit(train_data_df, train_labels)\n",
    "  y_pred = clf.predict(test_data_df)\n",
    "  print(metrics.classification_report(test_labels, y_pred, zero_division=0))\n",
    "\n",
    "evaluateClassifier(LogisticRegression(solver='saga', max_iter = 1000, C=100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSw1OczAAgb3"
   },
   "source": [
    "### Q3c:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2711327S_Coursework",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
